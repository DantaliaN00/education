We have extended our raytracer by implementing 2x antialiasing, 
edge detection, and transparent objects.

We have implemented 2x antialiasing by shooting 4 rays per pixel
in the final image output, and taking the average of their color
values:

[unantialiased image] [antialiased  image]

We use the Sobel operator to detect edges. We can call

./raytracer -j ourImage.scenefile

to convolve the Sobel operator with the image rendered from the 
scenefile.

[example image]

With ./raytracer -k value ourImage.scenefile, instead of convolving the rendered
scene with the Sobel operator, we generate a schematic of the
edges of the scene, displaying edges as red outlines, with
sensitivity to edges based on the number passed into the flag.

[example image]


We combine the ideas of anti-aliasing and edge detection to
perform anti-aliasing only on pixels corresponding to an edge.
This results in a final image that looks almost as good as
the fully anti-aliased image, but renders much more quickly
because of the reduced number of pixels that need to have
multiple rays generated. We shoot additional rays only for
pixels which correspond to edges, with sensitivity according
to the value passed into the flag.

./raytracer -m 0.2 


[example fully anti-aliased]
[same only with edge anti alias]
[no anti alias]


We have implemented transparent objects with the additional 
scenefile descriptor *alpha float*. When a ray intersects
with an object whose alpha is less than 1.0, it calculates
the current color as if the object were opaque, weights
that by the specified alpha value for that object,
and then adds that to the color generated by another 
ray shot from that location on the object in the same
direction as the original ray, weighted by 1 - alpha.
In this scene, we see a partially transparent sphere
in front of an opaque sphere and a translucent triangle
in front of an emissive triangle.

[alpha example]

